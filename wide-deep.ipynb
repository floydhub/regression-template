{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Prediction with a Wide & Deep Model\n",
    "\n",
    "Hi üôÇ, if you are seeing this notebook, you have succesfully started your first project on FloydHub üöÄ, hooray!!\n",
    "\n",
    "![wine-price](images/wineprice.png)\n",
    "\n",
    "In this notebook we will build a classifier to correctly predict the price of a wine from its description. More in detail, we will combine the strengh of ML and DL learning using a Wide & Deep Model, which provides really good performance for Regression and Reccomendation tasks.\n",
    "\n",
    "## Resource\n",
    "\n",
    "The code is based on this [terrific blog post](https://medium.com/tensorflow/predicting-the-price-of-wine-with-the-keras-functional-api-and-tensorflow-a95d1c2c1b03) ([official repo](https://github.com/sararob/keras-wine-model)). If you are interested in the topic, we also encourage you to read more about Wide & Deep models [here](https://www.tensorflow.org/tutorials/wide_and_deep) and [here](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html). \n",
    "\n",
    "The dataset was taken from [Kaggle](https://www.kaggle.com/zynicide/wine-reviews).\n",
    "\n",
    "![dataset](images/dataset.png)\n",
    "\n",
    "**Note**\n",
    "\n",
    "For executing a Code Cell, click on the Cell and run `Shift + Enter` (shortcut for Run)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "Let's start by importing the packages, Setting the training variables and loading the csv file from which get all the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install h5py==2.8.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 321,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2880,
     "status": "error",
     "timestamp": 1505781339378,
     "user": {
      "displayName": "Sara Robinson",
      "photoUrl": "//lh4.googleusercontent.com/-RR9n0dvbwgI/AAAAAAAAAAI/AAAAAAAAMYM/SOr5ZExpvXE/s50-c-k-no/photo.jpg",
      "userId": "112510032804989247452"
     },
     "user_tz": 240
    },
    "id": "783h64rGhA3T",
    "outputId": "d447b2ab-e321-4ee5-abd4-de2c0116302f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73025</th>\n",
       "      <td>73025</td>\n",
       "      <td>Israel</td>\n",
       "      <td>A soft acetone streak permeates the red cherry...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>87</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Galilee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>Bazelet HaGolan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19083</th>\n",
       "      <td>19083</td>\n",
       "      <td>US</td>\n",
       "      <td>Full, forward and loaded with ripe strawberry ...</td>\n",
       "      <td>Carpe Noctum</td>\n",
       "      <td>90</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Aberrant Cellars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>The top wine in the Rocim range is produced fr...</td>\n",
       "      <td>Grande Rocim Reserva</td>\n",
       "      <td>91</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alicante Bouschet</td>\n",
       "      <td>Herdade do Rocim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44581</th>\n",
       "      <td>44581</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Elegant but still holding back aromatically, t...</td>\n",
       "      <td>Molino della Suga</td>\n",
       "      <td>88</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Tuscany</td>\n",
       "      <td>Brunello di Montalcino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sangiovese Grosso</td>\n",
       "      <td>Bonacchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25879</th>\n",
       "      <td>25879</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>A soft, juicy wine, one-dimensional but attrac...</td>\n",
       "      <td>Terra Grande Colheita</td>\n",
       "      <td>85</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Parras Vinhos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   country  \\\n",
       "73025       73025    Israel   \n",
       "19083       19083        US   \n",
       "335           335  Portugal   \n",
       "44581       44581     Italy   \n",
       "25879       25879  Portugal   \n",
       "\n",
       "                                             description  \\\n",
       "73025  A soft acetone streak permeates the red cherry...   \n",
       "19083  Full, forward and loaded with ripe strawberry ...   \n",
       "335    The top wine in the Rocim range is produced fr...   \n",
       "44581  Elegant but still holding back aromatically, t...   \n",
       "25879  A soft, juicy wine, one-dimensional but attrac...   \n",
       "\n",
       "                 designation  points  price    province  \\\n",
       "73025                Reserve      87   60.0     Galilee   \n",
       "19083           Carpe Noctum      90   48.0      Oregon   \n",
       "335     Grande Rocim Reserva      91  130.0  Alentejano   \n",
       "44581      Molino della Suga      88   40.0     Tuscany   \n",
       "25879  Terra Grande Colheita      85   11.0  Alentejano   \n",
       "\n",
       "                     region_1           region_2            variety  \\\n",
       "73025                     NaN                NaN             Merlot   \n",
       "19083       Willamette Valley  Willamette Valley         Pinot Noir   \n",
       "335                       NaN                NaN  Alicante Bouschet   \n",
       "44581  Brunello di Montalcino                NaN  Sangiovese Grosso   \n",
       "25879                     NaN                NaN     Portuguese Red   \n",
       "\n",
       "                 winery  \n",
       "73025   Bazelet HaGolan  \n",
       "19083  Aberrant Cellars  \n",
       "335    Herdade do Rocim  \n",
       "44581          Bonacchi  \n",
       "25879     Parras Vinhos  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "\n",
    "# For reproducibility\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "# Set training given hardware\n",
    "if tf.test.is_gpu_available():\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 10\n",
    "    MAX_LEN = 170\n",
    "    VOCAB_SIZE = 1000\n",
    "    EMBEDDING = 8\n",
    "else:\n",
    "    BATCH_SIZE = 128\n",
    "    EPOCHS = 10\n",
    "    MAX_LEN = 170\n",
    "    VOCAB_SIZE = 1000\n",
    "    EMBEDDING = 8\n",
    "    \n",
    "path = '/floyd//data/winereviews/wine_data.csv'\n",
    "# Convert the data to a Pandas data frame\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Print the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we will perform data cleaning and splitting, useful for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 95646\n",
      "Test size: 23912\n"
     ]
    }
   ],
   "source": [
    "# Do some preprocessing to limit the # of wine varities in the dataset\n",
    "# Clean it from null values\n",
    "data = data[pd.notnull(data['country'])]\n",
    "data = data[pd.notnull(data['price'])]\n",
    "data = data.drop(data.columns[0], axis=1) \n",
    "\n",
    "variety_threshold = 500 # Anything that occurs less than this will be removed.\n",
    "value_counts = data['variety'].value_counts()\n",
    "to_remove = value_counts[value_counts <= variety_threshold].index\n",
    "data.replace(to_remove, np.nan, inplace=True)\n",
    "data = data[pd.notnull(data['variety'])]\n",
    "\n",
    "# Split data into train and test\n",
    "train_size = int(len(data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at data. The plot 'Tokens per sentence' is useful for setting the MAX_LEN variable, since we are building a static computational graph, we need to know the max lenght before starting the computation. This information is really helpful for building the deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucVXW9//HXWxDxGipkBhhoaD+6qXEU0zqmpnhJrLxgHkWzyPJS2ckwe4THsqPW0aPp0VAp9ZiXzJS8pOQl7RQIilcUHRFj+KGMoWiZJvo5f3y/k4s5s2c2zNp7z2bez8djP2at77p91oLZn/mu73d9lyICMzOzMqzV6ADMzGzN4aRiZmalcVIxM7PSOKmYmVlpnFTMzKw0TipmZlYaJxVbI0kaJ6ml0XGY9TVOKtZrSfpL4fOWpL8V5g9rdHzNStL7JK1odBy2Zurf6ADMKomIDdqnJS0EvhARv21cRLUlqX9E+MvempprKta0JK0r6QJJSyS1SvqhpLUrrPtNSQ9Lelee/3Sef0nSvZJGF9Z9TtLXJT0qabmkKyUNqLDfYyTdKeknkl6WNE/SxwvLN5F0ed7nIklTJK3VYdsLJL0ITO5k/ztLmpv3/Zykfy8s+5ikWfkcHpC0c2HZzHysmXnbWyRtnBffA/Qr1Pq2y9t8SdJ8Scsk3SxpaC4fKCkkTZL0tKQXJZ3TIc6vSHpC0iuSHpH0wVw+XNKNkl6QtEDSMV3+o1rziwh//On1H2AhsEeHsrOAe4HBwGbAbOCUvGwc0JKnfwDMAjbJ82OBJcBHgH7AJOBJoH9e/hzwP3mfQ4AW4MgKcR0DrAC+AqwNHAEsAzbKy28FfgysB2wOzAUmdtj2izmOdTvZ/1zgoDy9IbBjnh4B/BnYg/TH4T5AG7BxXj4TmA9sBawP/AE4NS97H7Ciw3EOAR4Hts7n8X3grrxsIBDA9cBGwEjgJWDXvPxw4FlgO0DANsCwfE6PAN8CBuR9/wn450b/f/Kndh/XVKyZHQZMiYgXIuJ50hfh4YXlknQBsBMpIS3L5V8Czo+I+yPizYiYCqxDSjLtzomI5yOiDbgF2LaLOBZFxH9FxBsRcTnQCuwl6T3Ax4ETI+LViFgCnAdMKGy7ICIuznH8rZN9vwFsLWnTiHglImbl8onA9RHx24h4KyJuAeYBexa2vTgino6IvwLXdXMOxwDfj4gnI+IN4N+AXSRtVljnBxHxckQ8Q6rttO/vC3nZ3EjmR0QrsAswMCLOjIi/R8STwE87nL+tYdymYk1JkoB3kf5CbvcsMLQw/07gKOBTEfFKofw9wMGSvlkoG9Bh2+cK06+SakOVtHaYfxZ4dz7OQKAthQukWkWxV9qiLvYLKXmcCjyZe7N9NyJuy/s+VNJBhXXXzsetdA4bUNl7gItyEm63glTjWN7N/oYDT1fY5whJLxXK+gFrbLuYOalYk4qIkPQc6Yur/QttC2BxYbXnSbelfi5pv4iYncsXATdHxH+UFM6wDvNbAP8/H+cvpFtSlYYD73KY8Ih4HDhEUj/SX/jX57aRRcAlEXH8asTb2TEXAd+MiF92XCBpYDf7W0S6zdYxWSwCnoiID65GjNakfPvLmtlVwBRJm0p6J3AK8N/FFSLiduDzwK/bG6SBqcDxksYo2UDS/pLWW804hudG9/6S/oX0l/vt+TbRTOAsSRtKWkvSKEm7VLtjSUfkW19vkmoMkT+XAQdJ2l1Sv9xpYff2jgjdWEpqqN+iUHYR8B1J2+Tjbizps1WGeQkwWdKH8/XcWtIw4Pd5X1/Ljf39JX1I0vZV7teakJOKNbPvktoRHgMeJDWun9VxpYi4GfgycKukD0XE/wAnAD8hNTg/CXyObmoNXbiH1Ei9jJTYPhMR7beMDgUGAU/k5deQOgBUaz9gvqRXgH8HDs5tNwuAz5LaPl4g3XL7KlX8TkfEi6TrdH/uObZtRFwFnE+qCb1Mup6frCbAiLgCOJvUbvNK/jkot83sA3w0x9cGXEjXt+GsyalyrdzMupO7yB4YEXs0Ohaz3sA1FTMzK42TipmZlca3v8zMrDSuqZiZWWn63HMqgwcPjhEjRjQ6DDOzpnL//fe/EBFDuluvzyWVESNGMGfOnEaHYWbWVCQ92/1avv1lZmYlclIxM7PSOKmYmVlpapZUJE2TtFTSo50s+0Z+6c/gPC9J50lqUXpx0vaFdSdKeip/JhbKP5JfBtSSt1XH45iZWX3VsqbyM9KLklYiaTjpnQ9/KhTvDYzKn0mk8YGQtAkwBdgR2IE0eGD72+suJL3cqH27/3MsMzOrr5ollYi4hzSAXkfnACex8uB944HL8wt+ZgKDJG0O7AXMiIhleRC8GcC4vGyjiJiZhxS/HDigVudiZmbVqWubiqTxwOKIeKjDoqGs/LKi1lzWVXlrJ+WVjjtJ0hxJc9ra2npwBmZm1pW6JZX8ropvk4Yrr6uImBoRYyJizJAh3T67Y2Zmq6meNZWtgJHAQ5IWkt6W90B+qdBi0ouN2g3LZV2VD+uk3MzMGqhuT9RHxCOkd4YDkBPLmIh4QdJ04DhJV5Ma5ZdHxBJJtwE/KDTO7wmcHBHLJL0saSwwCzgC+HG9zsXKM2LyzZ2WLzxj3zpHYmZlqGWX4quAPwLbSGqVdHQXq98CLABagItJ7xUnIpYB3wNm589puYy8ziV5m6eBW2txHmZmVr2a1VQi4tBulo8oTAdwbIX1pgHTOimfA3ygZ1GamVmZ/ES9mZmVxknFzMxK46RiZmalcVIxM7PSOKmYmVlpnFTMzKw0TipmZlYaJxUzMyuNk4qZmZXGScXMzErjpGJmZqVxUjEzs9I4qZiZWWmcVMzMrDROKmZmVhonFTMzK42TipmZlcZJxczMSuOkYmZmpXFSMTOz0jipmJlZaWqWVCRNk7RU0qOFsh9KekLSw5J+JWlQYdnJklokzZe0V6F8XC5rkTS5UD5S0qxcfo2kAbU6FzMzq04tayo/A8Z1KJsBfCAiPgQ8CZwMIGk0MAF4f97mvyT1k9QPuADYGxgNHJrXBTgTOCci3gu8CBxdw3MxM7Mq1CypRMQ9wLIOZbdHxIo8OxMYlqfHA1dHxOsR8QzQAuyQPy0RsSAi/g5cDYyXJGA34Lq8/WXAAbU6FzMzq04j21Q+D9yap4cCiwrLWnNZpfJNgZcKCaq9vFOSJkmaI2lOW1tbSeGbmVlHDUkqkk4BVgBX1uN4ETE1IsZExJghQ4bU45BmZn1S/3ofUNKRwH7A7hERuXgxMLyw2rBcRoXyPwODJPXPtZXi+mZm1iB1ralIGgecBOwfEa8WFk0HJkhaR9JIYBRwHzAbGJV7eg0gNeZPz8noLuDAvP1E4MZ6nYeZmXWull2KrwL+CGwjqVXS0cD5wIbADEkPSroIICIeA64F5gG/AY6NiDdzLeQ44DbgceDavC7At4ATJbWQ2lgurdW5mJlZdWp2+ysiDu2kuOIXf0ScDpzeSfktwC2dlC8g9Q4zM7Newk/Um5lZaZxUzMysNE4qZmZWGicVMzMrjZOKmZmVxknFzMxK46RiZmalcVIxM7PSOKmYmVlpnFTMzKw0TipmZlYaJxUzMyuNk4qZmZXGScXMzEpT9zc/Wt80YvLNjQ7BzOrANRUzMyuNk4qZmZXGScXMzErjpGJmZqVxUjEzs9I4qZiZWWlqllQkTZO0VNKjhbJNJM2Q9FT+uXEul6TzJLVIeljS9oVtJub1n5I0sVD+EUmP5G3Ok6RanYuZmVWnljWVnwHjOpRNBu6IiFHAHXkeYG9gVP5MAi6ElISAKcCOwA7AlPZElNf5YmG7jscyM7M6q1lSiYh7gGUdiscDl+Xpy4ADCuWXRzITGCRpc2AvYEZELIuIF4EZwLi8bKOImBkRAVxe2JeZmTVIvdtUNouIJXn6OWCzPD0UWFRYrzWXdVXe2kl5pyRNkjRH0py2traenYGZmVXUsIb6XMOIOh1rakSMiYgxQ4YMqcchzcz6pHonlefzrSvyz6W5fDEwvLDesFzWVfmwTsrNzKyB6j2g5HRgInBG/nljofw4SVeTGuWXR8QSSbcBPyg0zu8JnBwRyyS9LGksMAs4AvhxPU/EOlfWwJGV9rPwjH1L2b+Z1UbNkoqkq4BdgcGSWkm9uM4ArpV0NPAscHBe/RZgH6AFeBU4CiAnj+8Bs/N6p0VEe+P/V0g9zNYFbs0fMzNroJollYg4tMKi3TtZN4BjK+xnGjCtk/I5wAd6EqOZmZXLT9SbmVlpnFTMzKw0TipmZlYaJxUzMyuNk4qZmZXGScXMzErjpGJmZqVxUjEzs9I4qZiZWWnqPfaXWY94TDCz3q3bmoqkrSStk6d3lXSCpEG1D83MzJpNNbe/fgm8Kem9wFTSUPQ/r2lUZmbWlKpJKm9FxArg08CPI+KbwOa1DcvMzJpRNUnlDUmHkt5/clMuW7t2IZmZWbOqJqkcBewEnB4Rz0gaCVxR27DMzKwZddv7KyLmSfoWsEWefwY4s9aBmZlZ8+k2qUj6FPAjYAAwUtK2pDcw7l/r4Kz3Kuu1wWa2Zqnm9tepwA7ASwAR8SCwZQ1jMjOzJlVVQ31ELO9Q9lYtgjEzs+ZWzRP1j0n6HNBP0ijgBOAPtQ3LzMyaUTU1leOB9wOvA1cBLwNfq2VQZmbWnLpNKhHxakScEhH/FBFj8vRrPTmopK9LekzSo5KukjRQ0khJsyS1SLpG0oC87jp5viUvH1HYz8m5fL6kvXoSk5mZ9VzF21+Sfg1EpeWr2/tL0lDSLbTREfE3SdcCE4B9gHMi4mpJFwFHAxfmny9GxHslTSB1Zz5E0ui83fuBdwO/lbR1RLy5OnGZmVnPddWm8qMaH3ddSW8A6wFLgN2Az+Xll5F6nV0IjM/TANcB50tSLr86Il4HnpHUQuql9scaxm1mZl2omFQi4nft0/lW1PtINZf5EfH31T1gRCyW9CPgT8DfgNuB+4GX8hhjAK3A0Dw9FFiUt10haTmwaS6fWdh1cZuVSJoETALYYostVjd0MzPrRjVD3+8LPA2cB5wPtEjae3UPKGljUi1jJOm21frAuNXdXzUiYmpuDxozZMiQWh7KzKxPq6ZL8X8An4iIFkjvVwFuBm5dzWPuATwTEW15f9cDOwODJPXPtZVhwOK8/mLScPutkvoD7wD+XChvV9zGzMwaoJouxa+0J5RsAfBKD475J2CspPVy28juwDzgLuDAvM5E4MY8PT3Pk5ffGRGRyyfk3mEjgVHAfT2Iy8zMeqiamsocSbcA15LaVA4CZkv6DEBEXL8qB4yIWZKuAx4AVgBzSS//uhm4WtL3c9mleZNLgStyQ/wyUo8vIuKx3HNsXt7Pse75ZWbWWNUklYHA88A/5/k2YF3gU6Qks0pJBSAipgBTOhQvIPXe6rjua6RE1tl+TgdOX9Xjm5lZbVQz9P1R9QjEzMyaXzVD348kDdUyori+h743M7OOqrn9dQOpXePXeHRiMzPrQjVJ5bWIOK/mkZj1QKWXhi08Y986R2LWt1WTVM6VNIX05Pvr7YUR8UDNojIzs6ZUTVL5IHA4aWyu9ttfkedtDefXBpvZqqgmqRwEbNmT8b7MzKxvqOaJ+keBQbUOxMzMml81NZVBwBOSZrNym4q7FJuZ2UqqSSodn3w3MzPrVDVP1P+uu3XMzMyguvepjJU0W9JfJP1d0puSXq5HcGZm1lyqaag/HzgUeIo0kOQXgAtqGZSZmTWnapIK+X0q/SLizYj4KTV+U6OZmTWnahrqX83vqH9Q0lnAEqpMRmZm1rdUkxwOz+sdB/yV9Arfz9YyKDMza07V9P56Nk++Juk8YHiH1wubmZkB1fX+ulvSRpI2Ib0C+GJJZ9c+NDMzazbV3P56R0S8DHwGuDwidgT2qG1YZmbWjKppqO8vaXPgYOCUGsdjVqquRln2u1bMyldNTeU04DagJSJmS9qS9MyKmZnZSrpNKhHxi4j4UER8Jc8viIge9f6SNEjSdZKekPS4pJ0kbSJphqSn8s+N87qSdJ6kFkkPS9q+sJ+Jef2nJE3sSUxmZtZzjXre5FzgNxHxPuDDwOPAZOCOiBgF3JHnAfYGRuXPJOBCgNxxYAqwI7ADMKU9EZmZWWPUPalIegfwceBSgIj4e0S8BIwHLsurXQYckKfHkzoIRETMBAblNp69gBkRsSwiXgRm4Cf9zcwaqhE1lZFAG/BTSXMlXSJpfWCziFiS13kO2CxPDwUWFbZvzWWVyv8PSZMkzZE0p62trcRTMTOzomqeU/lOYXqdEo7ZH9geuDAitiM9pT+5uEJEBBAlHKt9f1MjYkxEjBkyZEhZuzUzsw4qJhVJ35K0E3BgofiPJRyzFWiNiFl5/jpSknk+39Yi/1yaly8mDQ3Tblguq1RuZmYN0lVN5QngIGBLSfdKuhjYVNI2PTlgRDwHLCrsZ3dgHjAdaO/BNRG4MU9PB47IvcDGAsvzbbLbgD0lbZwb6PfMZWZm1iBdPfz4EvBtYNf8+X+kL+7JkraJiI/24LjHA1fm0Y8XAEeREty1ko4GniU9bAlwC7AP0AK8mtclIpZJ+h4wO693WkQs60FMZmbWQ10llb2A7wJbAWcDDwN/jYijenrQiHgQGNPJot07WTeAYyvsZxowrafxmJlZOSre/oqIb0fE7sBC4AqgHzBE0u8l/bpO8ZmZWROpZuyv2yJiDjBH0pcjYhdJg2sdmJmZNZ9qhmk5qTB7ZC57oVYBmZlZ86qmpvIPEfFQrQKxxupqNF8zs2r5XfNmZlYaJxUzMyuNk4qZmZXGScXMzEqzSg31ZmuSSp0T/Jphs9XnmoqZmZXGScXMzErjpGJmZqVxUjEzs9I4qZiZWWmcVMzMrDROKmZmVhonFTMzK42TipmZlcZJxczMSuOkYmZmpXFSMTOz0jQsqUjqJ2mupJvy/EhJsyS1SLpG0oBcvk6eb8nLRxT2cXIuny9pr8aciZmZtWvkKMVfBR4HNsrzZwLnRMTVki4CjgYuzD9fjIj3SpqQ1ztE0mhgAvB+4N3AbyVtHRFv1vtEbM3i0YvNVl9DaiqShgH7ApfkeQG7AdflVS4DDsjT4/M8efnuef3xwNUR8XpEPAO0ADvU5wzMzKwzjaqp/CdwErBhnt8UeCkiVuT5VmBonh4KLAKIiBWSluf1hwIzC/ssbrMSSZOASQBbbLFFeWdhfYprMGbdq3tSkbQfsDQi7pe0az2OGRFTgakAY8aMiXocs7eq9MVoZlaGRtRUdgb2l7QPMJDUpnIuMEhS/1xbGQYszusvBoYDrZL6A+8A/lwob1fcxszMGqDubSoRcXJEDIuIEaSG9jsj4jDgLuDAvNpE4MY8PT3Pk5ffGRGRyyfk3mEjgVHAfXU6DTMz60Rvekf9t4CrJX0fmAtcmssvBa6Q1AIsIyUiIuIxSdcC84AVwLHu+WVm1lgNTSoRcTdwd55eQCe9tyLiNeCgCtufDpxeuwjNzGxV+Il6MzMrjZOKmZmVxknFzMxK46RiZmal6U29v6xEfsjRzBrBNRUzMyuNk4qZmZXGScXMzErjpGJmZqVxUjEzs9I4qZiZWWmcVMzMrDROKmZmVhonFTMzK42TipmZlcZJxczMSuOkYmZmpXFSMTOz0jipmJlZaZxUzMysNE4qZmZWmrq/pEvScOByYDMggKkRca6kTYBrgBHAQuDgiHhRkoBzgX2AV4EjI+KBvK+JwHfyrr8fEZfV81zMoPIL0RaesW+dIzFrvEbUVFYA34iI0cBY4FhJo4HJwB0RMQq4I88D7A2Myp9JwIUAOQlNAXYEdgCmSNq4nidiZmYrq3tSiYgl7TWNiHgFeBwYCowH2msalwEH5OnxwOWRzAQGSdoc2AuYERHLIuJFYAYwro6nYmZmHTS0TUXSCGA7YBawWUQsyYueI90eg5RwFhU2a81llco7O84kSXMkzWlraystfjMzW1nDkoqkDYBfAl+LiJeLyyIiSO0tpYiIqRExJiLGDBkypKzdmplZBw1JKpLWJiWUKyPi+lz8fL6tRf65NJcvBoYXNh+WyyqVm5lZg9Q9qeTeXJcCj0fE2YVF04GJeXoicGOh/AglY4Hl+TbZbcCekjbODfR75jIzM2uQuncpBnYGDgcekfRgLvs2cAZwraSjgWeBg/OyW0jdiVtIXYqPAoiIZZK+B8zO650WEcvqcwpmZtaZuieViPg9oAqLd+9k/QCOrbCvacC08qIzM7OeaERNxaxP8EOR1hd5mBYzMyuNaypNrNJfwmZmjeKaipmZlcZJxczMSuOkYmZmpXGbilmduVeYrclcUzEzs9I4qZiZWWmcVMzMrDROKmZmVho31DcBP+TYN7gB39YErqmYmVlpnFTMzKw0TipmZlYat6mY9XJua7Fm4qTSi7hB3syanZOKWZNyDcZ6IycVszWMk401khvqzcysNK6pNIDbTsxsTdX0SUXSOOBcoB9wSUSc0eCQzHqlrv6Y8a0xK0tTJxVJ/YALgE8CrcBsSdMjYl5jI0tcI7Fmsar/V52ErJKmTirADkBLRCwAkHQ1MB6oa1Jx8rC+ptb/5520mlezJ5WhwKLCfCuwY8eVJE0CJuXZv0ia381+BwMvlBJh+RzbquutcYFj65TO7HYVX7dV19O43lPNSs2eVKoSEVOBqdWuL2lORIypYUirzbGtut4aFzi21eXYVl294mr2LsWLgeGF+WG5zMzMGqDZk8psYJSkkZIGABOA6Q2Oycysz2rq218RsULSccBtpC7F0yLisRJ2XfWtsgZwbKuut8YFjm11ObZVV5e4FBH1OI6ZmfUBzX77y8zMehEnFTMzK42TSgeSxkmaL6lF0uQGxjFc0l2S5kl6TNJXc/kmkmZIeir/3LiBMfaTNFfSTXl+pKRZ+dpdkztPNCKuQZKuk/SEpMcl7dRbrpukr+d/z0clXSVpYKOum6RpkpZKerRQ1ul1UnJejvFhSdvXOa4f5n/PhyX9StKgwrKTc1zzJe1Vq7gqxVZY9g1JIWlwnq/bNesqNknH52v3mKSzCuW1uW4R4U/+kBr7nwa2BAYADwGjGxTL5sD2eXpD4ElgNHAWMDmXTwbObOD1OhH4OXBTnr8WmJCnLwK+3KC4LgO+kKcHAIN6w3UjPaz7DLBu4Xod2ajrBnwc2B54tFDW6XUC9gFuBQSMBWbVOa49gf55+sxCXKPz7+k6wMj8+9uvnrHl8uGkDkPPAoPrfc26uG6fAH4LrJPn31nr61bz/7jN9AF2Am4rzJ8MnNzouHIsN5LGOJsPbJ7LNgfmNyieYcAdwG7ATfkX54XCL/5K17KOcb0jf3GrQ3nDrxtvjwCxCann5U3AXo28bsCIDl9CnV4n4CfAoZ2tV4+4Oiz7NHBlnl7pdzR/se9Uz2uWy64DPgwsLCSVul6zCv+e1wJ7dLJeza6bb3+trLNhX4Y2KJZ/kDQC2A6YBWwWEUvyoueAzRoU1n8CJwFv5flNgZciYkWeb9S1Gwm0AT/Nt+YukbQ+veC6RcRi4EfAn4AlwHLgfnrHdWtX6Tr1pt+Nz5NqANAL4pI0HlgcEQ91WNTw2ICtgY/l26u/k/RPtY7NSaWXk7QB8EvgaxHxcnFZpD8x6t4nXNJ+wNKIuL/ex65Cf9ItgAsjYjvgr6TbOP/QwOu2MWnA05HAu4H1gXH1jqNajbpOXZF0CrACuLLRsQBIWg/4NvDdRsdSQX9SzXgs8E3gWkmq5QGdVFbWq4Z9kbQ2KaFcGRHX5+LnJW2el28OLG1AaDsD+0taCFxNugV2LjBIUvsDtY26dq1Aa0TMyvPXkZJMb7huewDPRERbRLwBXE+6lr3hurWrdJ0a/rsh6UhgP+CwnPB6Q1xbkf5IeCj/PgwDHpD0rl4QG6Tfh+sjuY90Z2FwLWNzUllZrxn2Jf81cSnweEScXVg0HZiYpyeS2lrqKiJOjohhETGCdI3ujIjDgLuAAxsc23PAIknb5KLdSa9CaPh1I932Gitpvfzv2x5bw69bQaXrNB04IvdoGgssL9wmqzmll/GdBOwfEa92iHeCpHUkjQRGAffVK66IeCQi3hkRI/LvQyupg81zNPiaZTeQGuuRtDWp48oL1PK61bLRqBk/pB4bT5J6Q5zSwDh2Id16eBh4MH/2IbVd3AE8RerVsUmDr9euvN37a8v8H7MF+AW5x0kDYtoWmJOv3Q3Axr3lugH/BjwBPApcQep905DrBlxFatt5g/RleHSl60TqiHFB/r14BBhT57haSG0A7b8LFxXWPyXHNR/Yu97XrMPyhbzdUF+3a9bFdRsA/Hf+//YAsFutr5uHaTEzs9L49peZmZXGScXMzErjpGJmZqVxUjEzs9I4qZiZWWmcVKypSPpLDfYpSXdK2qjsfXc4zt2SxtTyGPk4JyiNznxlh/JtJe1TxfanSvrXEuIYIuk3Pd2PNRcnFbP0/M9D0WEYnN6k8MR9Nb4CfDLSA6lF25LOtS4iog1YImnneh3TGs9JxZpe/ov4l5Jm58/OufzU/I6JuyUtkHRChV0cRn5yXNKI/Ff+xfn9E7dLWjcv+0dNQ9LgPCwHko6UdIPS+0cWSjpO0ol5QMuZkjYpHOtwSQ8qvU9lh7z9+jnO+/I24wv7nS7pTtIDiR3P+8S8n0clfS2XXUR6mPJWSV8vrDsAOA04JB//EKV3p9yg9K6PmZI+1MkxvijpVknrStpK0m8k3S/pXknvy+v8TOm9IX/I1/nAwi5uyNfX+op6PLnrjz9lfYC/dFL2c2CXPL0FaWgbgFOBP5CeWh8M/BlYu5PtnwU2zNMjSAMWbpvnrwX+JU/fTX4qOu9vYZ4+kvTE94bAENLow8fkZeeQBgNt3/7iPP1x8hDlwA8KxxhEGtFh/bzfVjp5+h/4COkp7fWBDYDHgO3ysoXkp7o7bHMkcH5h/sfAlDy9G/Bg4br9K3AcKdm2v4vjDmBUnt6RNDwPwM9IIwGsRXpPR0vhGEOBRxr9/8af+n1WpUpt1lvtAYwuDL66kdLozgA3R8TrwOuSlpKGcm/tsP0mEfFKYf6ZiHgwT99PSjTduSvv4xVJy4Ff5/JHgGIN4CqAiLhH0kZKbzDckzRAZ3s7xkBScgSYERHLOjkH4xKNAAAB7UlEQVTeLsCvIuKvAJKuBz4GzK0i1uI+PpvjuVPSpoV2pSNIw6IcEBFv5Ov5UeAXheu8TmFfN0TEW8A8ScXXCiwljchsfYSTiq0J1gLGRsRrxcL85fd6oehNOv8/v0LSWvlLsbNt1m1fj7dvGQ/ssI/iNm8V5t/qcMyO4yIFaYyoz0bE/A7x70gaur8RHiG1wQwjvfRsLdJ7X7atsH7x/ItDqw8E/laTCK1XcpuKrQluB45vn5FU6YuvkvmkdojuLCTddoK3RxVeVYcASNqFNGrtctJb947PIxcjabsq9nMvcEAe8Xh90tsQ7+1mm1dIt+iK+zgsH3NX4IV4u7PCXOBLwHRJ787lz0g6KK8vSR+uIs6tSYMZWh/hpGLNZj1JrYXPicAJwJjc4DwPOGYV93kzabTl7vwI+LKkuaQ2ldXxWt7+ItIosgDfA9YGHpb0WJ7vUkQ8QGrLuI/0RtBLIqK7W193kW4TPijpEFLbyUckPQycwdtD3rcf4/ektpWbJQ0mJaCjJT1EasMZ3/3p8gnS9bU+wqMUW5+n9DKqyyPik42OZU0j6R5gfES82OhYrD5cU7E+L9KLky6u9cOPfY2kIcDZTih9i2sqZmZWGtdUzMysNE4qZmZWGicVMzMrjZOKmZmVxknFzMxK87/UWzu1ZILo/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Custom Tokenizer\n",
    "re_tok = re.compile(f'([{string.punctuation}‚Äú‚Äù¬®¬´¬ª¬Æ¬¥¬∑¬∫¬Ω¬æ¬ø¬°¬ß¬£‚Ç§‚Äò‚Äô])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "# Plot sentence by lenght\n",
    "plt.hist([len(tokenize(s)) for s in data['description'].values], bins=50)\n",
    "plt.title('Token per sentence')\n",
    "plt.xlabel('Len (number of token)')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train features\n",
    "description_train = data['description'][:train_size]\n",
    "variety_train = data['variety'][:train_size]\n",
    "\n",
    "# Train labels\n",
    "labels_train = data['price'][:train_size]\n",
    "\n",
    "# Test features\n",
    "description_test = data['description'][train_size:]\n",
    "variety_test = data['variety'][train_size:]\n",
    "\n",
    "# Test labels\n",
    "labels_test = data['price'][train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Representation: BoW\n",
    "\n",
    "The Code below will encode the description of each sentence using the [BoW model](https://en.wikipedia.org/wiki/Bag-of-words_model). This representation will encode each sentence to a vector that keep track of the entries in the vocabulary which are used in the current sentences. This step will build a sparse vector(a vector with mostly zero values) for each description. The Code provides an example to help you get the intuition behind it.\n",
    "\n",
    "The **wide** term used for defining this model, is due to the sparse representation that this type of encoding carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "anD38iilhA3r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Original Sample: A soft acetone streak permeates the red cherry- and berry-driven bouquet, while red fruit and pomegranate flavors dominate the palate. A slightly twiggy herbal accent adds depth and staying power to the finish. Drink now.\n",
      "\n",
      "First Sample after BoW (sparse representation truncated at the first 100 vocabulary terms): [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"First Original Sample:\", data['description'].values[0])\n",
    "# Create a tokenizer to preprocess our text descriptions\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE, char_level=False)\n",
    "tokenizer.fit_on_texts(description_train) # only fit on train\n",
    "\n",
    "# Wide feature 1: sparse bag of words (bow) vocab_size vector \n",
    "description_bow_train = tokenizer.texts_to_matrix(description_train)\n",
    "description_bow_test = tokenizer.texts_to_matrix(description_test)\n",
    "print(\"\\nFirst Sample after BoW (sparse representation truncated at the first 100 vocabulary terms):\", description_bow_train[0][:100])\n",
    "\n",
    "# Wide feature 2: one-hot vector of variety categories\n",
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(variety_train)\n",
    "variety_train = encoder.transform(variety_train)\n",
    "variety_test = encoder.transform(variety_test)\n",
    "num_classes = np.max(variety_train) + 1\n",
    "\n",
    "# Convert labels to one hot\n",
    "variety_train = keras.utils.to_categorical(variety_train, num_classes)\n",
    "variety_test = keras.utils.to_categorical(variety_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Model\n",
    "\n",
    "The model will use the BoW representation for the *winde description* and One-Hot encoding representation for the *wine variety* as Features for the Wide Model (a 2 layers NN).\n",
    "\n",
    "![wide](images/wide.png)\n",
    "\n",
    "*Image from the [paper](https://arxiv.org/pdf/1606.07792.pdf)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1040)         0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          266496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 266,753\n",
      "Trainable params: 266,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define our wide model with the functional API\n",
    "bow_inputs = layers.Input(shape=(VOCAB_SIZE,))\n",
    "variety_inputs = layers.Input(shape=(num_classes,))\n",
    "merged_layer = layers.concatenate([bow_inputs, variety_inputs])\n",
    "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
    "predictions = layers.Dense(1)(merged_layer)\n",
    "wide_model = keras.Model(inputs=[bow_inputs, variety_inputs], outputs=predictions)\n",
    "\n",
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Representation: Embedding\n",
    "\n",
    "The Code below will encode the description of each sentence using [Word Embedding](https://en.wikipedia.org/wiki/Word_embedding). This representation will encode each word of the sentence into a vector. Before applying this encoding we need to preprocess the wine description by converting each token to an index and pad the sentence to the same lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Original Sample: A soft acetone streak permeates the red cherry- and berry-driven bouquet, while red fruit and pomegranate flavors dominate the palate. A slightly twiggy herbal accent adds depth and staying power to the finish. Drink now.\n",
      "\n",
      "First Sample after Preprocessing for Embedding: [  3  45 506   2  41  19   1  44 428 262  75  41  13   1 685   8 604   2\n",
      "  24   3 136 115 758 379 313   1 296  11   2  18  32  38   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(\"First Original Sample:\", data['description'].values[0])\n",
    "\n",
    "# Deep model feature: word embeddings of wine descriptions\n",
    "train_embed = tokenizer.texts_to_sequences(description_train)\n",
    "test_embed = tokenizer.texts_to_sequences(description_test)\n",
    "\n",
    "train_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_embed, maxlen=MAX_LEN, padding=\"post\")\n",
    "test_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_embed, maxlen=MAX_LEN, padding=\"post\")\n",
    "\n",
    "print(\"\\nFirst Sample after Preprocessing for Embedding:\", train_embed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Model\n",
    "\n",
    "This model build a liner layer at the top of the word embedding representaion of the wine description. \n",
    "\n",
    "![deep](images/deep.png)\n",
    "\n",
    "*Image from the [paper](https://arxiv.org/pdf/1606.07792.pdf)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 170, 8)            8000      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1360)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1361      \n",
      "=================================================================\n",
      "Total params: 9,361\n",
      "Trainable params: 9,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define our deep model with the Functional API\n",
    "deep_inputs = layers.Input(shape=(MAX_LEN,))\n",
    "embedding = layers.Embedding(VOCAB_SIZE, EMBEDDING, input_length=MAX_LEN)(deep_inputs)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embed_out = layers.Dense(1)(embedding)\n",
    "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
    "print(deep_model.summary())\n",
    "\n",
    "deep_model.compile(loss='mse',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide & Deep Model\n",
    "\n",
    "We will implement a model similar to Heng-Tze Cheng‚Äôs [Wide & Deep Learning for Recommender Systems](https://arxiv.org/pdf/1606.07792.pdf). \n",
    "\n",
    "This model catenate the output of the previous models and build an additional linear layer at the top.\n",
    "\n",
    "![wide & deep](images/wide&deep.png)\n",
    "\n",
    "*Image from the [paper](https://arxiv.org/pdf/1606.07792.pdf)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 170)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1040)         0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 170, 8)       8000        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          266496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1360)         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1361        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            3           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 276,117\n",
      "Trainable params: 276,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Combine wide and deep into one model\n",
    "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
    "merged_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
    "print(combined_model.summary())\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train& Eval\n",
    "\n",
    "The Training is defined at the beginning by the type of instance on which runs:\n",
    "\n",
    "- On a CPU instance it will train for 10 epoch in about 1 minute.\n",
    "- On a GPU instance it will train for 10 epoch in about 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gtP-hDRZhA31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95646/95646 [==============================] - 8s 80us/step - loss: 1173.5215 - acc: 0.0264\n",
      "Epoch 2/10\n",
      "95646/95646 [==============================] - 7s 73us/step - loss: 1004.0753 - acc: 0.0315\n",
      "Epoch 3/10\n",
      "95646/95646 [==============================] - 7s 73us/step - loss: 956.9435 - acc: 0.0328\n",
      "Epoch 4/10\n",
      "95646/95646 [==============================] - 7s 75us/step - loss: 909.4029 - acc: 0.0349\n",
      "Epoch 5/10\n",
      "95646/95646 [==============================] - 7s 74us/step - loss: 856.2370 - acc: 0.0343\n",
      "Epoch 6/10\n",
      "95646/95646 [==============================] - 7s 74us/step - loss: 801.5227 - acc: 0.0359\n",
      "Epoch 7/10\n",
      "95646/95646 [==============================] - 7s 74us/step - loss: 744.3661 - acc: 0.0361\n",
      "Epoch 8/10\n",
      "95646/95646 [==============================] - 7s 74us/step - loss: 688.6710 - acc: 0.0362\n",
      "Epoch 9/10\n",
      "95646/95646 [==============================] - 7s 73us/step - loss: 632.3834 - acc: 0.0359\n",
      "Epoch 10/10\n",
      "95646/95646 [==============================] - 7s 73us/step - loss: 573.7606 - acc: 0.0364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7ff35ea62710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "combined_model.fit([description_bow_train, variety_train] + [train_embed], labels_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23912/23912 [==============================] - 1s 22us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[799.7232393103326, 0.034961525596959926]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.evaluate([description_bow_test, variety_test] + [test_embed], labels_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843f6ce76c4f436eb5ada995b5ab0040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='# of test to evaluate/show', max=20, min=1), Output()), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def evaluate(num_predictions):\n",
    "    # Generate predictions\n",
    "    predictions = combined_model.predict([description_bow_test, variety_test] + [test_embed])\n",
    "\n",
    "    # Compare predictions with actual values for the first few items in our test dataset\n",
    "    diff = 0\n",
    "    for i in range(num_predictions):\n",
    "        val = predictions[i]\n",
    "        print('[{}] - {}'.format(i+1, description_test.iloc[i]))\n",
    "        print('Predicted: ', val[0], 'Actual: ', labels_test.iloc[i], '\\n')\n",
    "        diff += abs(val[0] - labels_test.iloc[i])\n",
    "\n",
    "    # Compare the average difference between actual price and the model's predicted price\n",
    "    print('Average prediction difference: ', diff / num_predictions)\n",
    "\n",
    "interact(evaluate, num_predictions=widgets.IntSlider(value=1, min=1, max=20, description='# of test to evaluate/show'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's your turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "[6, 9, 475, 27, 19, 50, 299, 5, 20, 4, 27, 147, 1, 193, 5, 3, 140, 51, 18]\n",
      "From 18-year-old vines, this supple well-balanced effort blends flavors of mocha, cherry, vanilla and breakfast tea. Superbly integrated and delicious even at this early stage, this wine seems destined for a long and savory cellar life. Drink now through 2028.\n",
      "Predicted:  46.473076 Actual:  48 \n",
      "\n",
      "The Quarts de Chaume, the four fingers of land that rise above the Layon Valley, are one of the pinnacles of sweet wines in the Loire. Showing botrytis and layers of dryness over the honey and peach jelly flavors, but also has great freshness. The aftertaste just lasts.\n",
      "Predicted:  55.323677 Actual:  152 \n",
      "\n",
      "Nicely oaked blackberry, licorice, vanilla and charred aromas are smooth and sultry. This is an outstanding wine from an excellent year. Forward barrel-spice and mocha flavors adorn core blackberry and raspberry fruit, while this runs long and tastes vaguely chocolaty on the velvety finish. Enjoy this top-notch Tempranillo through 2030.\n",
      "Predicted:  50.221573 Actual:  80 \n",
      "\n",
      "Bright, light oak shadings dress up this medium-bodied wine, complementing the red cherry and strawberry flavors. Its fresh, fruity and not very tannic‚Äîeasy to drink and enjoy.\n",
      "Predicted:  17.749008 Actual:  10 \n",
      "\n",
      "This wine features black cherry, blackberry, blueberry with aromas of black licorice and earth. Ending with a creamy vanilla finish.\n",
      "Predicted:  24.521069 Actual:  23 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's make predictions on some raw data\n",
    "\n",
    "# Enter wine descriptions here\n",
    "test_descriptions = [\n",
    "    'From 18-year-old vines, this supple well-balanced effort blends flavors of mocha, cherry, vanilla and breakfast tea. Superbly integrated and delicious even at this early stage, this wine seems destined for a long and savory cellar life. Drink now through 2028.',\n",
    "    'The Quarts de Chaume, the four fingers of land that rise above the Layon Valley, are one of the pinnacles of sweet wines in the Loire. Showing botrytis and layers of dryness over the honey and peach jelly flavors, but also has great freshness. The aftertaste just lasts.',\n",
    "    'Nicely oaked blackberry, licorice, vanilla and charred aromas are smooth and sultry. This is an outstanding wine from an excellent year. Forward barrel-spice and mocha flavors adorn core blackberry and raspberry fruit, while this runs long and tastes vaguely chocolaty on the velvety finish. Enjoy this top-notch Tempranillo through 2030.',\n",
    "    'Bright, light oak shadings dress up this medium-bodied wine, complementing the red cherry and strawberry flavors. Its fresh, fruity and not very tannic‚Äîeasy to drink and enjoy.',\n",
    "    'This wine features black cherry, blackberry, blueberry with aromas of black licorice and earth. Ending with a creamy vanilla finish.'\n",
    "]\n",
    "\n",
    "# Enter the corresponding varieties here\n",
    "test_varieties = [\n",
    "    'Pinot Noir',\n",
    "    'Chenin Blanc',\n",
    "    'Tempranillo',\n",
    "    'Sauvignon Blanc',\n",
    "    'Syrah'\n",
    "]\n",
    "\n",
    "# Enter the corresponding prices here\n",
    "labels = [\n",
    "    48,\n",
    "    152,\n",
    "    80,\n",
    "    10,\n",
    "    23\n",
    "]\n",
    "\n",
    "# Wide model features\n",
    "bow_description = tokenizer.texts_to_matrix(test_descriptions)\n",
    "variety = encoder.transform(test_varieties)\n",
    "print(variety[4])\n",
    "variety = keras.utils.to_categorical(variety, len(encoder.classes_))\n",
    "\n",
    "# Print an example for the model inputs\n",
    "# print(\"Bag of words matrix\")\n",
    "# print(bow_description[0], \"\\n\")\n",
    "# print(\"Variety matrix\")\n",
    "# print(variety[0], \"\\n\")\n",
    "\n",
    "# Deep model feature: word embeddings of wine descriptions\n",
    "embed_description = tokenizer.texts_to_sequences(test_descriptions)\n",
    "print(embed_description[4])\n",
    "embed_description = keras.preprocessing.sequence.pad_sequences(\n",
    "    embed_description, maxlen=MAX_LEN, padding=\"post\")\n",
    "\n",
    "\n",
    "\n",
    "predictions = combined_model.predict([bow_description, variety] + [embed_description])\n",
    "for i in range(len(test_descriptions)):\n",
    "    val = predictions[i]\n",
    "    print(test_descriptions[i])\n",
    "    print('Predicted: ', val[0], 'Actual: ', labels[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have prepared some custom descriptions for testing. Run the code Cell below and type your wine description and variety in the widget, have fun :)\n",
    "\n",
    "- **Description**: 'From 18-year-old vines, this supple well-balanced effort blends flavors of mocha, cherry, vanilla and breakfast tea. Superbly integrated and delicious even at this early stage, this wine seems destined for a long and savory cellar life. Drink now through 2028.', **Variety**: 'Pinot Noir'.\n",
    "- **Description**: 'The Quarts de Chaume, the four fingers of land that rise above the Layon Valley, are one of the pinnacles of sweet wines in the Loire. Showing botrytis and layers of dryness over the honey and peach jelly flavors, but also has great freshness. The aftertaste just lasts.', **Variety**: 'Chenin Blanc'.\n",
    "- **Description**: 'Nicely oaked blackberry, licorice, vanilla and charred aromas are smooth and sultry. This is an outstanding wine from an excellent year. Forward barrel-spice and mocha flavors adorn core blackberry and raspberry fruit, while this runs long and tastes vaguely chocolaty on the velvety finish. Enjoy this top-notch Tempranillo through 2030.', **Variety**: 'Tempranillo'.\n",
    "- **Description**: 'Bright, light oak shadings dress up this medium-bodied wine, complementing the red cherry and strawberry flavors. Its fresh, fruity and not very tannic‚Äîeasy to drink and enjoy.', **Variety**: 'Sauvignon Blanc'.\n",
    "- **Description**: 'This wine features black cherry, blackberry, blueberry with aromas of black licorice and earth. Ending with a creamy vanilla finish.', **Variety**: 'Syrah'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52f5d81051f45e7b24de274cbd31430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='test_description', placeholder='Type a wine Description ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "def get_prediction(test_description, test_variety):\n",
    "    # Wide model features\n",
    "    bow_description = tokenizer.texts_to_matrix([test_description])\n",
    "    variety = encoder.transform([test_variety])\n",
    "    variety = keras.utils.to_categorical(variety, len(encoder.classes_))\n",
    "    \n",
    "    # Deep model feature: word embeddings of wine descriptions\n",
    "    embed_description = tokenizer.texts_to_sequences([test_description])\n",
    "    embed_description = keras.preprocessing.sequence.pad_sequences(\n",
    "        embed_description, maxlen=MAX_LEN, padding=\"post\")\n",
    "    \n",
    "\n",
    "    # Evaluate\n",
    "    predictions = combined_model.predict([bow_description, variety] + [embed_description])\n",
    "    print(test_description)\n",
    "    print('Predicted: ', predictions[0][0])\n",
    "    \n",
    "interact_manual(get_prediction, \n",
    "                test_description=widgets.Textarea(placeholder='Type a wine Description here'),\n",
    "                test_variety=widgets.Text(placeholder='Type a wine Variety here'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving Tokenizer\n",
    "with open('models/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    " \n",
    "# Saving Variety Encode\n",
    "with open('models/encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Saving Model Weight\n",
    "combined_model.save_weights('models/wide_and_deep_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "keras-wide-deep.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
